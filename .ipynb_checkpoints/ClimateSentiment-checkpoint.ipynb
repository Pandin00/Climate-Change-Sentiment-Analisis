{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5277b8ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\luket\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raccolta dei post da Reddit in corso...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'lenght'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12860\\3398657028.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    103\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Raccolta dei post da Reddit in corso...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m     \u001b[0mposts_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfetch_reddit_posts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreddit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubreddits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpost_limit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 105\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mposts_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"numero post\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mposts_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlenght\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Visualizzazione del sentiment...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5573\u001b[0m         ):\n\u001b[0;32m   5574\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5575\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5576\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5577\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'lenght'"
     ]
    }
   ],
   "source": [
    "# Importazione delle librerie necessarie\n",
    "import praw\n",
    "from textblob import TextBlob\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import nltk\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "# Carica file env\n",
    "load_dotenv(dotenv_path=\"reddit.env\")\n",
    "\n",
    "# Impostazioni API di Reddit (da configurare con le proprie credenziali)\n",
    "CLIENT_ID = os.getenv(\"client_id\")\n",
    "CLIENT_SECRET = os.getenv(\"client_secret\")\n",
    "USER_AGENT = os.getenv(\"user_agent\")\n",
    "\n",
    "# Autenticazione con l'API di Reddit\n",
    "def authenticate_reddit():\n",
    "    reddit = praw.Reddit(\n",
    "        client_id=CLIENT_ID,\n",
    "        client_secret=CLIENT_SECRET,\n",
    "        user_agent=USER_AGENT\n",
    "    )\n",
    "    return reddit\n",
    "\n",
    "# Funzione per pulire il testo dei post\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'http\\S+', '', text)  # Rimuove i link\n",
    "    text = re.sub(r'[^a-zA-Z ]', '', text)  # Rimuove caratteri speciali\n",
    "    text = text.lower()  # Converte in minuscolo\n",
    "    return text\n",
    "\n",
    "# Funzione per analizzare il sentiment di un testo\n",
    "def analyze_sentiment(text):\n",
    "    analysis = TextBlob(text)\n",
    "    if analysis.sentiment.polarity > 0:\n",
    "        return 'positive'\n",
    "    elif analysis.sentiment.polarity < 0:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'neutral'\n",
    "\n",
    "# Funzione per rilevare emozioni specifiche utilizzando SentimentIntensityAnalyzer\n",
    "def detect_emotion(text):\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "    scores = sid.polarity_scores(text)\n",
    "    if scores['neg'] > 0.5:\n",
    "        return 'anger'\n",
    "    elif 'fear' in text or scores['neg'] > 0.3 and scores['neu'] < 0.5:\n",
    "        return 'fear'\n",
    "    elif scores['pos'] > 0.5:\n",
    "        return 'joy'\n",
    "    elif scores['neg'] > 0.3 and 'sad' in text:\n",
    "        return 'sadness'\n",
    "    elif 'ecoanxiety' in text or 'climate anxiety' in text:\n",
    "        return 'ecoanxiety'\n",
    "    else:\n",
    "        return 'neutral'\n",
    "\n",
    "# Funzione per raccogliere i post basati su una parola chiave\n",
    "def fetch_reddit_posts(reddit, subreddits, query, limit):\n",
    "    post_data = []\n",
    "    \n",
    "\n",
    "    posts = reddit.subreddit(\"+\".join(subreddits)).hot()\n",
    "    for post in posts:\n",
    "        cleaned_text = clean_text(post.title + ' ' + post.selftext)\n",
    "        sentiment = analyze_sentiment(cleaned_text)\n",
    "        emotion = detect_emotion(cleaned_text)\n",
    "        post_data.append({ 'title': post.title, 'text': cleaned_text, 'sentiment': sentiment, 'emotion': emotion})\n",
    "    return pd.DataFrame(post_data)\n",
    "\n",
    "# Funzione per visualizzare i risultati del sentiment\n",
    "def plot_sentiment(df):\n",
    "    sentiment_counts = df['sentiment'].value_counts()\n",
    "    sentiment_counts.plot(kind='bar', color=['green', 'red', 'blue'])\n",
    "    plt.title('Distribuzione del Sentiment')\n",
    "    plt.xlabel('Sentiment')\n",
    "    plt.ylabel('Numero di Post')\n",
    "    plt.show()\n",
    "\n",
    "# Funzione per visualizzare i risultati delle emozioni\n",
    "def plot_emotions(df):\n",
    "    emotion_counts = df['emotion'].value_counts()\n",
    "    emotion_counts.plot(kind='bar', color=['yellow', 'orange', 'gray', 'purple', 'cyan', 'black'])\n",
    "    plt.title('Distribuzione delle Emozioni')\n",
    "    plt.xlabel('Emozioni')\n",
    "    plt.ylabel('Numero di Post')\n",
    "    plt.show()\n",
    "\n",
    "# Esecuzione principale\n",
    "if __name__ == \"__main__\":\n",
    "    reddit = authenticate_reddit()\n",
    "    subreddits = [\"climate\", \"environment\", \"sustainability\", \"globalwarming\", \"climatechange\"]\n",
    "    query = \"climate change\"\n",
    "    post_limit = 1000\n",
    "\n",
    "    print(\"Raccolta dei post da Reddit in corso...\")\n",
    "    posts_df = fetch_reddit_posts(reddit, subreddits, query, post_limit)\n",
    "    print(posts_df.head())\n",
    "    print(\"numero post:\") print(posts_df.lenght)\n",
    "\n",
    "    print(\"Visualizzazione del sentiment...\")\n",
    "    plot_sentiment(posts_df)\n",
    "\n",
    "    print(\"Visualizzazione delle emozioni...\")\n",
    "    plot_emotions(posts_df)\n",
    "\n",
    "    # Salvataggio dei risultati\n",
    "    posts_df.to_csv('climate_change_sentiment_emotions_reddit.csv', index=False)\n",
    "    print(\"Risultati salvati in 'climate_change_sentiment_emotions_reddit.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476d7a92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a47869",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
